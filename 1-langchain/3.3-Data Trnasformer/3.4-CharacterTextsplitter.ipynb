{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ‚ï¸ CharacterTextSplitter - Simple Single-Separator Splitting\n",
    "\n",
    "## What is CharacterTextSplitter?\n",
    "\n",
    "The **simplest** text splitter in LangChain. It splits text based on a **single character** (or sequence).\n",
    "\n",
    "## How It Differs from RecursiveCharacterTextSplitter\n",
    "\n",
    "| Feature | CharacterTextSplitter | RecursiveCharacterTextSplitter |\n",
    "|---------|----------------------|-------------------------------|\n",
    "| Separators | Single (`\\n\\n` by default) | Multiple, tries in order |\n",
    "| Complexity | Simple | Smart |\n",
    "| Best for | Known structure | General text |\n",
    "| Preserves | Less semantic meaning | More semantic meaning |\n",
    "\n",
    "## Key Parameters:\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `separator` | `\"\\n\\n\"` | The character(s) to split on |\n",
    "| `chunk_size` | 4000 | Maximum chunk size |\n",
    "| `chunk_overlap` | 200 | Characters shared between chunks |\n",
    "| `is_separator_regex` | `False` | Treat separator as regex |\n",
    "\n",
    "## When to Use? ğŸ¤”\n",
    "\n",
    "âœ… **Use CharacterTextSplitter when:**\n",
    "- Your text has a known, consistent structure\n",
    "- You want splits at specific points (e.g., paragraphs)\n",
    "- Simplicity is preferred over semantic preservation\n",
    "\n",
    "âŒ **Use RecursiveCharacterTextSplitter when:**\n",
    "- Text structure is unknown or varies\n",
    "- Semantic meaning preservation is important\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Loading the Document\n",
    "\n",
    "First, let's load a text file to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loaded 1 document(s)\n",
      "ğŸ“ Content length: 3624 characters\n",
      "\n",
      "--- Preview (first 300 chars) ---\n",
      "The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are \n"
     ]
    }
   ],
   "source": [
    "# Load a text document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('speech.txt')\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"ğŸ“„ Loaded {len(docs)} document(s)\")\n",
    "print(f\"ğŸ“ Content length: {len(docs[0].page_content)} characters\")\n",
    "print(f\"\\n--- Preview (first 300 chars) ---\")\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Using CharacterTextSplitter with Documents\n",
    "\n",
    "Split loaded documents using `split_documents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 470, which is longer than the specified 100\n",
      "Created a chunk of size 347, which is longer than the specified 100\n",
      "Created a chunk of size 668, which is longer than the specified 100\n",
      "Created a chunk of size 982, which is longer than the specified 100\n",
      "Created a chunk of size 789, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Original: 1 document(s)\n",
      "ğŸ“Š After splitting: 7 chunks\n",
      "\n",
      "--- Chunk 1 (470 chars) ---\n",
      "The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\n",
      "\n",
      "--- Chunk 2 (347 chars) ---\n",
      "Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\n",
      "\n",
      "--- Chunk 3 (1 chars) ---\n",
      "â€¦\n"
     ]
    }
   ],
   "source": [
    "# Import CharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Create splitter with explicit separator\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",      # Split on double newlines (paragraphs)\n",
    "    chunk_size=100,        # Max 100 characters per chunk\n",
    "    chunk_overlap=20       # 20 character overlap\n",
    ")\n",
    "\n",
    "# Split the documents\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"ğŸ“Š Original: {len(docs)} document(s)\")\n",
    "print(f\"ğŸ“Š After splitting: {len(split_docs)} chunks\")\n",
    "\n",
    "# Show first few chunks\n",
    "for i, chunk in enumerate(split_docs[:3]):\n",
    "    print(f\"\\n--- Chunk {i+1} ({len(chunk.page_content)} chars) ---\")\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Using CharacterTextSplitter with Raw Strings\n",
    "\n",
    "Use `create_documents()` when you have raw text strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 470, which is longer than the specified 100\n",
      "Created a chunk of size 347, which is longer than the specified 100\n",
      "Created a chunk of size 668, which is longer than the specified 100\n",
      "Created a chunk of size 982, which is longer than the specified 100\n",
      "Created a chunk of size 789, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Created 7 chunks\n",
      "\n",
      "==================================================\n",
      "ğŸ“„ CHUNK 1:\n",
      "==================================================\n",
      "Length: 470 characters\n",
      "The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\n",
      "\n",
      "==================================================\n",
      "ğŸ“„ CHUNK 2:\n",
      "==================================================\n",
      "Length: 347 characters\n",
      "Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\n"
     ]
    }
   ],
   "source": [
    "# Read file as raw string\n",
    "with open(\"speech.txt\") as f:\n",
    "    speech = f.read()\n",
    "\n",
    "# Create splitter (using default separator \\n\\n)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "# create_documents() takes a list of strings\n",
    "text_chunks = text_splitter.create_documents([speech])\n",
    "\n",
    "print(f\"ğŸ“Š Created {len(text_chunks)} chunks\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“„ CHUNK 1:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Length: {len(text_chunks[0].page_content)} characters\")\n",
    "print(text_chunks[0].page_content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“„ CHUNK 2:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Length: {len(text_chunks[1].page_content)} characters\")\n",
    "print(text_chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Custom Separators\n",
    "\n",
    "You can use any character or string as a separator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ Key Takeaways\n",
    "\n",
    "### CharacterTextSplitter vs RecursiveCharacterTextSplitter\n",
    "\n",
    "```\n",
    "CharacterTextSplitter:          RecursiveCharacterTextSplitter:\n",
    "        â†“                                    â†“\n",
    "   One separator                    Multiple separators\n",
    "   (e.g., \"\\n\\n\")                  [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        â†“                                    â†“\n",
    "   Split text                       Try first separator\n",
    "        â†“                                    â†“\n",
    "   Done!                           Chunks still too big?\n",
    "                                            â†“\n",
    "                                   Try next separator...\n",
    "```\n",
    "\n",
    "### Common Separators:\n",
    "\n",
    "| Separator | Use Case |\n",
    "|-----------|----------|\n",
    "| `\"\\n\\n\"` | Paragraphs (default) |\n",
    "| `\"\\n\"` | Lines |\n",
    "| `\". \"` | Sentences |\n",
    "| `\" \"` | Words |\n",
    "| `\",\"` | CSV-like data |\n",
    "\n",
    "### Best Practices ğŸ’¡\n",
    "\n",
    "1. âœ… Use when text has consistent structure\n",
    "2. âœ… Choose separator based on your content\n",
    "3. âš ï¸ For unknown structure, use RecursiveCharacterTextSplitter\n",
    "4. ğŸ”„ Always test chunk sizes with your data\n",
    "\n",
    "### Next Steps ğŸš€\n",
    "- Try **HTMLHeaderTextSplitter** for structured HTML\n",
    "- Explore **RecursiveJsonSplitter** for JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 470, which is longer than the specified 150\n",
      "Created a chunk of size 347, which is longer than the specified 150\n",
      "Created a chunk of size 668, which is longer than the specified 150\n",
      "Created a chunk of size 982, which is longer than the specified 150\n",
      "Created a chunk of size 789, which is longer than the specified 150\n",
      "Created a chunk of size 856, which is longer than the specified 200\n",
      "Created a chunk of size 468, which is longer than the specified 200\n",
      "Created a chunk of size 342, which is longer than the specified 200\n",
      "Created a chunk of size 340, which is longer than the specified 200\n",
      "Created a chunk of size 748, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Splitting on '\\n' creates 7 chunks\n",
      "ğŸ“Š Splitting on '. ' creates 12 chunks\n"
     ]
    }
   ],
   "source": [
    "# Example: Split on single newlines instead\n",
    "single_line_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",        # Split on single newlines\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "chunks = single_line_splitter.create_documents([speech])\n",
    "print(f\"ğŸ“Š Splitting on '\\\\n' creates {len(chunks)} chunks\")\n",
    "\n",
    "# Example: Split on periods (sentences)\n",
    "sentence_splitter = CharacterTextSplitter(\n",
    "    separator=\". \",        # Split on sentence boundaries\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=30\n",
    ")\n",
    "\n",
    "sentence_chunks = sentence_splitter.create_documents([speech])\n",
    "print(f\"ğŸ“Š Splitting on '. ' creates {len(sentence_chunks)} chunks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
