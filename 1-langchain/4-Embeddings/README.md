# ğŸ“š LangChain Embeddings - Complete Learning Guide

Welcome to the **Embeddings Module** of the LangChain learning series! This guide provides a comprehensive overview of text embeddings and how to use them with LangChain.

---

## ğŸ—ºï¸ Module Overview

```mermaid
graph TB
    subgraph "ğŸ“– 4-Embeddings Module"
        A[4.1 OpenAI Embeddings] --> D[Vector Stores]
        B[4.2 Ollama Embeddings] --> D
        C[4.3 HuggingFace Embeddings] --> D
        D --> E[Similarity Search]
        E --> F[RAG Applications]
    end
    
    style A fill:#10a37f,color:#fff
    style B fill:#ff6b6b,color:#fff
    style C fill:#ffcc00,color:#000
    style D fill:#6c5ce7,color:#fff
    style E fill:#00b894,color:#fff
    style F fill:#0984e3,color:#fff
```

---

## ğŸ¯ What Are Embeddings?

**Embeddings** transform text into numerical vectors that capture semantic meaning. Similar texts have similar vectors, enabling powerful semantic search and AI applications.

```mermaid
flowchart LR
    subgraph Input
        T1["ğŸ”¤ 'Hello World'"]
        T2["ğŸ”¤ 'Hi Everyone'"]
        T3["ğŸ”¤ 'Buy groceries'"]
    end
    
    subgraph "Embedding Model"
        E[("ğŸ§  Neural Network")]
    end
    
    subgraph "Vector Space"
        V1["ğŸ“ [0.12, -0.45, ...]"]
        V2["ğŸ“ [0.11, -0.44, ...]"]
        V3["ğŸ“ [0.87, 0.23, ...]"]
    end
    
    T1 --> E --> V1
    T2 --> E --> V2
    T3 --> E --> V3
    
    V1 -.->|"Close (Similar)"| V2
    V1 -.->|"Far (Different)"| V3
```

---

## ğŸ““ Notebooks in This Module

| # | Notebook | Provider | Cost | Description |
|---|----------|----------|------|-------------|
| 1 | [4.1-embedding.ipynb](4.1-embedding.ipynb) | ğŸŸ¢ **OpenAI** | ğŸ’° Paid | Cloud-based, highest quality embeddings |
| 2 | [4.2-ollamaemnedding.ipynb](4.2-ollamaemnedding.ipynb) | ğŸ¦™ **Ollama** | ğŸ†“ Free | Local, private embedding generation |
| 3 | [4.3-huggingface.ipynb](4.3-huggingface.ipynb) | ğŸ¤— **HuggingFace** | ğŸ†“ Free | Open-source sentence transformers |

---

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "ğŸ“„ Documents"
        DOC[Raw Text Documents]
    end
    
    subgraph "ğŸ“ Processing"
        LOAD[Document Loader]
        SPLIT[Text Splitter]
    end
    
    subgraph "ğŸ§  Embedding Options"
        OAI[OpenAI API]
        OLL[Ollama Local]
        HF[HuggingFace]
    end
    
    subgraph "ğŸ—ƒï¸ Storage"
        VS[(Vector Store<br/>ChromaDB)]
    end
    
    subgraph "ğŸ” Retrieval"
        QUERY[User Query]
        SEARCH[Similarity Search]
        RESULTS[Relevant Chunks]
    end
    
    DOC --> LOAD --> SPLIT
    SPLIT --> OAI & OLL & HF
    OAI & OLL & HF --> VS
    QUERY --> OAI & OLL & HF
    VS --> SEARCH
    QUERY -.-> SEARCH
    SEARCH --> RESULTS
    
    style OAI fill:#10a37f,color:#fff
    style OLL fill:#ff6b6b,color:#fff
    style HF fill:#ffcc00,color:#000
    style VS fill:#6c5ce7,color:#fff
```

---

## ğŸ“Š Provider Comparison

### Feature Matrix

| Feature | OpenAI | Ollama | HuggingFace |
|---------|:------:|:------:|:-----------:|
| **Cost** | ğŸ’° Paid | ğŸ†“ Free | ğŸ†“ Free |
| **Privacy** | â˜ï¸ Cloud | ğŸ  Local | ğŸ  Local |
| **Quality** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **Speed** | âš¡âš¡âš¡âš¡ | âš¡âš¡ | âš¡âš¡âš¡ |
| **Offline** | âŒ | âœ… | âœ… |
| **Setup** | API Key | Install App | pip install |

### Embedding Dimensions

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'pie1': '#10a37f', 'pie2': '#ff6b6b', 'pie3': '#ffcc00', 'pie4': '#6c5ce7'}}}%%
pie showData
    title Embedding Dimensions by Model
    "OpenAI (3072)" : 3072
    "Ollama mxbai (1024)" : 1024
    "HuggingFace mpnet (768)" : 768
    "HuggingFace MiniLM (384)" : 384
```

---

## ğŸ”§ Quick Start Guide

### 1ï¸âƒ£ OpenAI Embeddings (Best Quality)

```python
from langchain_openai import OpenAIEmbeddings

# Initialize
embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

# Embed text
vector = embeddings.embed_query("Your text here")
```

### 2ï¸âƒ£ Ollama Embeddings (Free & Local)

```python
from langchain_community.embeddings import OllamaEmbeddings

# Initialize (requires Ollama installed)
embeddings = OllamaEmbeddings(model="mxbai-embed-large")

# Embed text
vector = embeddings.embed_query("Your text here")
```

### 3ï¸âƒ£ HuggingFace Embeddings (Open Source)

```python
from langchain_huggingface import HuggingFaceEmbeddings

# Initialize
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Embed text
vector = embeddings.embed_query("Your text here")
```

---

## ğŸ”„ The RAG Pipeline

```mermaid
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant E as ğŸ§  Embeddings
    participant V as ğŸ—ƒï¸ Vector Store
    participant L as ğŸ¤– LLM
    
    Note over U,L: ğŸ“¥ Indexing Phase
    U->>E: Load Documents
    E->>E: Split into Chunks
    E->>E: Generate Embeddings
    E->>V: Store Vectors
    
    Note over U,L: ğŸ” Query Phase
    U->>E: Ask Question
    E->>E: Embed Query
    E->>V: Similarity Search
    V->>E: Return Top K Results
    E->>L: Query + Context
    L->>U: Generated Answer
```

---

## ğŸ“ˆ Learning Path

```mermaid
graph LR
    A[ğŸ“š Start Here] --> B[4.1 OpenAI<br/>Learn Basics]
    B --> C[4.2 Ollama<br/>Local Models]
    C --> D[4.3 HuggingFace<br/>Open Source]
    D --> E[ğŸ¯ Build RAG App]
    
    style A fill:#e74c3c,color:#fff
    style B fill:#10a37f,color:#fff
    style C fill:#ff6b6b,color:#fff
    style D fill:#ffcc00,color:#000
    style E fill:#0984e3,color:#fff
```

### Recommended Order:

1. **[4.1-embedding.ipynb](4.1-embedding.ipynb)** - Start here to understand embedding fundamentals with OpenAI
2. **[4.2-ollamaemnedding.ipynb](4.2-ollamaemnedding.ipynb)** - Learn about local, free alternatives
3. **[4.3-huggingface.ipynb](4.3-huggingface.ipynb)** - Explore the open-source ecosystem

---

## ğŸ“ Key Concepts

### Embedding Methods

| Method | Purpose | Example Use |
|--------|---------|-------------|
| `embed_query()` | Single text | Search queries |
| `embed_documents()` | Multiple texts | Document indexing |

### Text Splitting Parameters

| Parameter | Description | Typical Value |
|-----------|-------------|---------------|
| `chunk_size` | Max characters per chunk | 500-1000 |
| `chunk_overlap` | Shared chars between chunks | 50-100 |

### Vector Store Operations

| Operation | Description |
|-----------|-------------|
| `from_documents()` | Create store from docs |
| `similarity_search()` | Find similar chunks |
| `add_documents()` | Add new documents |

---

## ğŸ“¦ Dependencies

```bash
# Core
pip install langchain langchain-community

# OpenAI
pip install langchain-openai

# HuggingFace
pip install langchain-huggingface sentence-transformers

# Vector Store
pip install chromadb

# Environment
pip install python-dotenv
```

---

## ğŸ”— Additional Resources

- ğŸ“– [LangChain Documentation](https://python.langchain.com/docs/modules/data_connection/text_embedding/)
- ğŸ§  [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- ğŸ¦™ [Ollama Embedding Models](https://ollama.com/blog/embedding-models)
- ğŸ¤— [HuggingFace Sentence Transformers](https://huggingface.co/sentence-transformers)
- ğŸ“Š [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)

---

## âœ… Summary Checklist

After completing this module, you should be able to:

- [ ] Explain what embeddings are and why they're useful
- [ ] Use OpenAI embeddings with LangChain
- [ ] Set up local embeddings with Ollama
- [ ] Use HuggingFace sentence transformers
- [ ] Load and split documents for embedding
- [ ] Store embeddings in ChromaDB
- [ ] Perform similarity search on embedded documents
- [ ] Choose the right embedding provider for your use case

---

<div align="center">

**Happy Learning! ğŸš€**

*Created as part of the LangChain Learning Series*

</div>
