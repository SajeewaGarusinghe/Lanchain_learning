# ğŸ—„ï¸ Vector Stores in LangChain

## ğŸ“š Overview

Welcome to the **Vector Stores** module! This section covers how to store and retrieve document embeddings efficiently using vector databases - a crucial component for building semantic search and RAG (Retrieval Augmented Generation) applications.

> ğŸ’¡ **From the Instructor**: *"Two of the most common things that we use which are completely open source are FAISS and Chroma. As we go ahead, when we develop end-to-end projects, we'll be seeing new DBs like Cassandra DB, Astra DB, and Pinecone - which can be hosted in the cloud."*

---

## ğŸ¯ What are Vector Stores?

Vector stores are specialized databases designed to store and search **high-dimensional vectors** (embeddings). They enable **semantic search** - finding documents based on meaning rather than exact keyword matches.

### ğŸ§  The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         VECTOR STORE PIPELINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ“„ INDEXING PHASE                                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                           â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚Documents â”‚â”€â”€â”€â–¶â”‚  Text    â”‚â”€â”€â”€â–¶â”‚Embedding â”‚â”€â”€â”€â–¶â”‚   Vector Store   â”‚      â”‚
â”‚  â”‚  (.txt,  â”‚    â”‚ Splitter â”‚    â”‚  Model   â”‚    â”‚  (FAISS/Chroma)  â”‚      â”‚
â”‚  â”‚  .pdf)   â”‚    â”‚          â”‚    â”‚          â”‚    â”‚                  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚       â”‚               â”‚               â”‚                   â”‚                 â”‚
â”‚       â–¼               â–¼               â–¼                   â–¼                 â”‚
â”‚   Raw Text      Chunks of       Numerical           Indexed for            â”‚
â”‚                  Text           Vectors             Fast Search            â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  ğŸ” RETRIEVAL PHASE                                                         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                         â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  User    â”‚â”€â”€â”€â–¶â”‚ Embeddingâ”‚â”€â”€â”€â–¶â”‚  Similarity      â”‚â”€â”€â”€â–¶â”‚ Relevant â”‚      â”‚
â”‚  â”‚  Query   â”‚    â”‚  Model   â”‚    â”‚  Search          â”‚    â”‚ Documentsâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚       â”‚               â”‚                   â”‚                   â”‚             â”‚
â”‚       â–¼               â–¼                   â–¼                   â–¼             â”‚
â”‚   "What is..."   Query Vector     Compare with all      Top K matches      â”‚
â”‚                                   stored vectors                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Notebooks in This Module

| # | Notebook | Description | Key Concepts |
|---|----------|-------------|--------------|
| 1 | [5.1-Faiss.ipynb](5.1-Faiss.ipynb) | ğŸš€ Facebook AI Similarity Search | Fast similarity search, L2 distance |
| 2 | [5.2-Chroma.ipynb](5.2-Chroma.ipynb) | ğŸ¨ AI-native vector database | Built-in persistence, metadata filtering |

### ğŸ“¹ Lecture Transcripts
| File | Description |
|------|-------------|
| [Faiss_lecture.txt](Faiss_lecture.txt) | ğŸ“ Complete FAISS tutorial walkthrough |
| [chromadb_lecture.txt](chromadb_lecture.txt) | ğŸ“ Complete Chroma DB tutorial walkthrough |

---

## ğŸ”§ Installation Guide

Before starting, make sure to install the required packages:

```bash
# For FAISS (CPU version - use faiss-gpu for cloud/GPU)
pip install faiss-cpu

# For Chroma (new LangChain integration)
pip install langchain-chroma

# Common dependencies
pip install langchain langchain-community
```

> âš ï¸ **Important Note**: In the previous version of Chroma, you would install `chromadb` separately. Now, LangChain has a dedicated library `langchain-chroma` that you should use instead. No need to install chromadb separately!

---

## ğŸ”‘ Key Concepts

### 1ï¸âƒ£ Embeddings

**What**: Numerical representations of text that capture semantic meaning.

```
"I love programming" â”€â”€â–¶ [0.12, -0.34, 0.56, 0.78, ...]
                              â”‚
                              â–¼
                        768-4096 dimensions
                        (depending on model)
```

**Why**: Computers can't understand text directly - embeddings allow mathematical comparison of meanings.

> ğŸ’¡ **Pro Tip**: You can also pass vectors directly instead of text! Use `embeddings.embed_query(query)` to get the vector, then use `similarity_search_by_vector(embedding_vector)` for more control.

### 2ï¸âƒ£ Text Splitting

**What**: Breaking large documents into smaller chunks.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Large Document                    â”‚
â”‚  (10,000 characters)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼ Text Splitter
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1â”‚    â”‚ Chunk 2â”‚    â”‚ Chunk 3â”‚
â”‚ (1000) â”‚    â”‚ (1000) â”‚    â”‚ (1000) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Types**:
| Splitter | Best For |
|----------|----------|
| `CharacterTextSplitter` | Simple, fixed-size splitting |
| `RecursiveCharacterTextSplitter` | Preserves document structure |
| `TokenTextSplitter` | Token-aware splitting |

### 3ï¸âƒ£ Similarity Search

**What**: Finding the most similar vectors to a query.

```
Query: "What is machine learning?"
         â”‚
         â–¼ Embed
    [0.2, 0.5, ...]
         â”‚
         â–¼ Compare
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Doc1: [0.2, 0.5, ...] â†’ Score: 0.1â”‚ âœ… Best match
    â”‚  Doc2: [0.3, 0.4, ...] â†’ Score: 0.3â”‚
    â”‚  Doc3: [0.8, 0.1, ...] â†’ Score: 0.9â”‚ âŒ Least similar
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4ï¸âƒ£ Retrievers - The Interface Pattern

**What**: A standardized interface that connects vector stores to LLM models.

> ğŸ’¡ **From the Instructor**: *"Retrievers are like an interface which, whenever we put any kind of query, is connected to the vector store DB. We need to convert the vector store DB into a retriever class. This allows us to easily work with other LangChain methods which largely work with retrievers."*

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHY USE RETRIEVERS?                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  âŒ WITHOUT RETRIEVER:                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Vector Storeâ”‚ â”€â”€â”€â”€ âœ— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚   LLM   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  (Can't connect    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                    directly!)                                    â”‚
â”‚                                                                  â”‚
â”‚  âœ… WITH RETRIEVER:                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Vector Storeâ”‚â”€â”€â”€â–¶â”‚ Retriever â”‚â”€â”€â”€â–¶â”‚   LLM   â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚        â”‚              (Interface)                                â”‚
â”‚        â–¼                   â”‚                                     â”‚
â”‚  db.as_retriever()    retriever.invoke(query)                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Point**: When working with different LLM models, you cannot directly use the vector store DB. You must first convert it into a retriever!

---

## ğŸ†š Vector Store Comparison

### FAISS vs Chroma

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VECTOR STORE COMPARISON                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚       FAISS         â”‚       â”‚       CHROMA        â”‚          â”‚
â”‚  â”‚   (Meta AI)         â”‚       â”‚   (Chroma Inc)      â”‚          â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚
â”‚  â”‚ âš¡ Ultra-fast       â”‚       â”‚ ğŸ¯ Developer-friendlyâ”‚          â”‚
â”‚  â”‚ ğŸ”¢ Billions vectors â”‚       â”‚ ğŸ’¾ Built-in persist â”‚          â”‚
â”‚  â”‚ ğŸ§® Multiple indexes â”‚       â”‚ ğŸ·ï¸ Rich metadata    â”‚          â”‚
â”‚  â”‚ ğŸ“ˆ Production-ready â”‚       â”‚ ğŸ”Œ Easy setup       â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚  BEST FOR:                     BEST FOR:                        â”‚
â”‚  â€¢ Large-scale search          â€¢ Rapid prototyping              â”‚
â”‚  â€¢ Performance-critical apps   â€¢ Metadata filtering             â”‚
â”‚  â€¢ Massive datasets            â€¢ Small-medium datasets          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Feature Matrix

| Feature | FAISS | Chroma |
|---------|:-----:|:------:|
| **Speed** | â­â­â­â­â­ | â­â­â­â­ |
| **Ease of Use** | â­â­â­ | â­â­â­â­â­ |
| **Persistence** | Manual (`save_local()`) | Built-in (`persist_directory`) |
| **Metadata Filtering** | Limited | Rich |
| **Scalability** | Excellent | Good |
| **GPU Support** | âœ… (`faiss-gpu`) | âŒ |
| **Client-Server** | âŒ | âœ… |
| **Internal Storage** | Binary files (`.faiss`, `.pkl`) | SQLite DB (`.sqlite3`) |
| **License** | MIT | Apache 2.0 |

> ğŸ’¡ **Storage Details**:
> - **FAISS**: Saves as `index.faiss` (vectors) + `index.pkl` (metadata)
> - **Chroma**: Creates a `chroma.sqlite3` database internally - *"Every vector is stored inside this particular DB. This can be hosted anywhere you like!"*

---

## ğŸ”„ Common Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAG (Retrieval Augmented Generation)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚   1. LOAD              2. SPLIT            3. EMBED            4. STORE     â”‚
â”‚   â•â•â•â•â•â•â•             â•â•â•â•â•â•â•â•â•â•â•         â•â•â•â•â•â•â•â•â•           â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ PDF  â”‚            â”‚ Chunked  â”‚        â”‚Vectors â”‚          â”‚ Vector  â”‚   â”‚
â”‚   â”‚ TXT  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Text    â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ [...]  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Store  â”‚   â”‚
â”‚   â”‚ Web  â”‚            â”‚          â”‚        â”‚        â”‚          â”‚         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                     â”‚        â”‚
â”‚                                                                     â–¼        â”‚
â”‚   5. RETRIEVE         6. AUGMENT          7. GENERATE                       â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•         â•â•â•â•â•â•â•â•â•â•          â•â•â•â•â•â•â•â•â•â•â•                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚   â”‚ Relevant â”‚        â”‚ Query +  â”‚        â”‚  LLM    â”‚                       â”‚
â”‚   â”‚   Docs   â”‚â—€â”€â”€â”€â”€â”€â”€â–¶â”‚ Context  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚Response â”‚                       â”‚
â”‚   â”‚          â”‚        â”‚          â”‚        â”‚         â”‚                       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Quick Start Code

### FAISS Example
```python
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OllamaEmbeddings

# Create
db = FAISS.from_documents(docs, OllamaEmbeddings())

# Search
results = db.similarity_search("your query")

# Persist
db.save_local("faiss_index")
```

### Chroma Example
```python
from langchain_chroma import Chroma
from langchain_community.embeddings import OllamaEmbeddings

# Create (with persistence)
db = Chroma.from_documents(
    docs, 
    OllamaEmbeddings(),
    persist_directory="./chroma_db"
)

# Search
results = db.similarity_search("your query")

# Load later
db = Chroma(persist_directory="./chroma_db", embedding_function=OllamaEmbeddings())
```

---

## ğŸ“Š Understanding Similarity Scores

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DISTANCE METRICS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  L2 (Euclidean) Distance - Used by FAISS & Chroma            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•              â”‚
â”‚                                                                â”‚
â”‚  Score = 0.0   â”€â”€â–¶  ğŸ¯ Perfect match (identical)              â”‚
â”‚  Score < 0.5   â”€â”€â–¶  ğŸŸ¢ Very similar                           â”‚
â”‚  Score < 1.0   â”€â”€â–¶  ğŸŸ¡ Somewhat similar                       â”‚
â”‚  Score > 1.5   â”€â”€â–¶  ğŸ”´ Not very similar                       â”‚
â”‚                                                                â”‚
â”‚  âš ï¸ LOWER score = BETTER match                                â”‚
â”‚                                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                â”‚
â”‚  Cosine Similarity (alternative metric)                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                     â”‚
â”‚                                                                â”‚
â”‚  Score = 1.0   â”€â”€â–¶  ğŸ¯ Perfect match                          â”‚
â”‚  Score > 0.8   â”€â”€â–¶  ğŸŸ¢ Very similar                           â”‚
â”‚  Score > 0.5   â”€â”€â–¶  ğŸŸ¡ Somewhat similar                       â”‚
â”‚  Score < 0.5   â”€â”€â–¶  ğŸ”´ Not similar                            â”‚
â”‚                                                                â”‚
â”‚  âš ï¸ HIGHER score = BETTER match                               â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> ğŸ’¡ **From the Instructor**: *"The returned distance score is L2 distance, which is also called Manhattan distance. Therefore, a lower score is better. Based on that particular information, whichever is the nearest, that will be getting as the first context from that particular text file."*

### Using Similarity Search with Score

```python
# Get documents WITH their similarity scores
docs_and_scores = db.similarity_search_with_score(query)

for doc, score in docs_and_scores:
    print(f"Score: {score:.4f} - {doc.page_content[:50]}...")
```

---

## ğŸš€ Best Practices

### 1. Chunk Size Selection
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CHUNK SIZE TRADE-OFFS                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Small Chunks (100-500 chars)                               â”‚
â”‚  â”œâ”€ âœ… More precise retrieval                               â”‚
â”‚  â”œâ”€ âœ… Less noise in results                                â”‚
â”‚  â””â”€ âŒ May lose context                                     â”‚
â”‚                                                              â”‚
â”‚  Large Chunks (1000-2000 chars)                             â”‚
â”‚  â”œâ”€ âœ… More context preserved                               â”‚
â”‚  â”œâ”€ âœ… Fewer chunks to search                               â”‚
â”‚  â””â”€ âŒ May include irrelevant info                          â”‚
â”‚                                                              â”‚
â”‚  ğŸ’¡ Recommendation: Start with 500-1000 and adjust          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Embedding Model Selection

| Model | Dimensions | Speed | Quality | Use Case |
|-------|-----------|-------|---------|----------|
| Ollama (local) | ~4096 | Medium | Good | Privacy, offline |
| OpenAI ada-002 | 1536 | Fast | Excellent | Production |
| HuggingFace | Varies | Medium | Good | Custom needs |

### 3. When to Use Which?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DECISION TREE: Choosing a Vector Store                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Need to handle billions of vectors?                        â”‚
â”‚  â”œâ”€ YES â”€â”€â–¶ Use FAISS                                       â”‚
â”‚  â””â”€ NO                                                       â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Need rich metadata filtering?                              â”‚
â”‚  â”œâ”€ YES â”€â”€â–¶ Use Chroma                                      â”‚
â”‚  â””â”€ NO                                                       â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Prototyping or small dataset?                              â”‚
â”‚  â”œâ”€ YES â”€â”€â–¶ Use Chroma (easier setup)                       â”‚
â”‚  â””â”€ NO â”€â”€â–¶ Use FAISS (better performance)                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Additional Resources

- ğŸ“– [LangChain Vector Stores Documentation](https://python.langchain.com/docs/modules/data_connection/vectorstores/)
- ğŸ”— [FAISS GitHub](https://github.com/facebookresearch/faiss)
- ğŸ¨ [Chroma Documentation](https://docs.trychroma.com/)
- ğŸ“º [Vector Databases Explained (YouTube)](https://www.youtube.com/watch?v=klTvEwg3oJ4)

---

## ğŸ—ºï¸ Vector Store Ecosystem

Beyond FAISS and Chroma, there are many other vector stores you'll encounter:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  VECTOR STORE LANDSCAPE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ğŸ†“ OPEN SOURCE (Local)          â˜ï¸ CLOUD-HOSTED                â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ â€¢ FAISS (Meta)      â”‚         â”‚ â€¢ Pinecone          â”‚        â”‚
â”‚  â”‚ â€¢ Chroma            â”‚         â”‚ â€¢ Astra DB          â”‚        â”‚
â”‚  â”‚ â€¢ Milvus            â”‚         â”‚   (Cassandra-based) â”‚        â”‚
â”‚  â”‚ â€¢ Weaviate          â”‚         â”‚ â€¢ Qdrant Cloud      â”‚        â”‚
â”‚  â”‚ â€¢ Qdrant            â”‚         â”‚ â€¢ Weaviate Cloud    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â”‚  ğŸ’¡ We'll explore Astra DB and Pinecone in end-to-end projects! â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Learning Checklist

- [ ] Understand what embeddings are and why we need them
- [ ] Learn different text splitting strategies
- [ ] Create a FAISS vector store from documents
- [ ] Create a Chroma vector store with persistence
- [ ] Perform similarity search with scores
- [ ] Convert vector stores to retrievers
- [ ] Save and load vector stores from disk
- [ ] Choose the right vector store for your use case

---

## ğŸ¯ Next Steps

After completing this module, you're ready to:

1. **Build a RAG System** - Combine vector stores with LLMs
2. **Explore Other Vector Stores** - Pinecone, Weaviate, Milvus, Astra DB
3. **Implement Hybrid Search** - Combine keyword + semantic search
4. **Add Metadata Filtering** - Filter results by custom attributes
5. **Deploy to Cloud** - Host your vector store on cloud services

---

## âš ï¸ Common Gotchas

| Issue | Solution |
|-------|----------|
| ğŸ¢ Embedding is slow locally | Use GPU (`faiss-gpu`) or cloud embedding services |
| ğŸ“¦ `chromadb` import error | Use `langchain-chroma` instead of `chromadb` directly |
| ğŸ”„ Can't use vector store with LLM | Convert to retriever first with `db.as_retriever()` |
| ğŸ’¾ Lost data after restart | Enable persistence: `save_local()` for FAISS, `persist_directory` for Chroma |
| âš¡ Need faster search | Consider FAISS with GPU or use approximate nearest neighbor indexes |

---

## ğŸ§ª Practice Exercises

1. **Basic**: Load a text file, split it, create a FAISS index, and search for a query
2. **Intermediate**: Compare results between FAISS and Chroma on the same dataset
3. **Advanced**: Build a simple Q&A system using a retriever + LLM

---

*Happy Learning! ğŸš€*
